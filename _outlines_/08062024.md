MILESTONE: Better UI and beginning nodes

For future ref: https://paulbatchelor.github.io/proj/soundpipe.html seems like a great library for dsp
 
- Frontend addons
    - (DONE) CSS addons
        - Install tailwind
    - Basic UI for nodes
        - (DONE) Blender style, colored header (different colors for different categories)
        - (Could be tricky, table for a sec) Have inputs all on left and outputs on right, these are below whatever internal settings a node has (like filepath for input)
        - (DONE) Nice and rounded
    - (NO REACTFLOW IS HARD) Better edge UI
        - Have so it when hovering over the edge a delete button pops up
            - Reactflow's documentation on custom edges literally does this
    - (DONE) Better top bar UI
        - (DONE) Figure out a nice layout for buttons and timeline, As well as a nice place for messages
            - 2 rows, first row has buttons on left and the timeline (with timeline controls) on right, timeline takes up 70-90% of row
            - second row has messages and progress bar
        - (STRETCH GOAL) Progress bar (???)
            - Just a simple text thing but we can very easily improve.
    - (DONE) Ditching our custom work and using shadcn
        - These are very pretty minimally styled components, I think we should go with these for now
        - Theyre copy and paste so theyd be very easy to modify in future
- Robustness
    - (DONE) Unified sampleconfig
        - (DONE) Player::new() creates the samplerate and sampleformat
            - put these in a struct thats Copy + Clone
        - (DONE) Attempting to do super dynamic stuff (our "native" format can be any rate and format) is overkill
            - We should have a central struct though that says what our "native" format is though, for future-proofing
                - I guess this is the former point we are making (Player::new() yadda yadda)
            - (DONE) So real thing is, for now, how do we make sure the HoundReader, whatever format it is, into our native one
                - SampleRate is easy: get the spec's samplerate and then pass that in to our eventual resampler.
                - Channels is easy: if its 1 then just write every sample twice, if its 2 then its just an effective copy.
                - SampleFormat needs a match statement on all possible formats, wihch we then convert.
                    - This should be a convert() method under the struct Player::new() will create. 
    - (DONE but broken and will need to be reworked with streaming) Playback position
        - Where is time and duration stored?
            - Have playbackposition send two usizes, one is current buffer idx and the other is current buffer len
                - with these numbers and the sample rate its very easy to figure out the time of the current sample and where we are in buffer 
- Nodes
    - (DONE) Waveform generation
        - Sine
        - Triangle
        - Square
        - Sawtooth

        - All of these need the same parameters of amplitude, frequency, and total time (ignore phaseshift for now lol)
            - Under the hood, these can all be the same node that has amplitude, frequency, and type in its JSON data
            - Put under seperate nodes visually tho cause I think that is nice.
        - Not stressing about generating these nodes, should be simple math.
    - Operations
        - Add,Sub,Mul
            - These would be one node with like a dropdown, call it "Binary Op" (idea is we oculd have unary later down the line)
            - Given A (op) B, what do we do if A is shorter than B, or vice versa?
                - Have two options, one for if len(A) < len(B) and if len(B) < len(A)
                    - For now, can either just always use 0, or use the last sample in the buffer.

NEXT MILESTONE (POTENTIALLY): streaming model + seeking?
    - seeking is easy but idc really bout it right now
        - actually this may be difficult with streaming (?)

NODE IDEAS:
    - L/R split
        - Split a sound buffer into two one channel buffers
            - If we dont want to start tracking channel # for buffers (which we probably want to do that seems important), we could just have it so each buffer is 2 channels,
            but the samples for both L and R channel are the same (its all L channel or all R channel of original buffer)
    - L/R add
        - Add two buffers into one buffer, left and right
            - How does this work if the inputs are two channel buffers?
                - Could just add the L and R channel together
                - This sort of hints at a larger problem - is this an AUDIO editor (in which case 2 channels can honestly just be the standard) or is this a GENERAL signal editor (in which case we should probably start differentiating between single vs 2 channel buffers)
                    - tbh I vote audio - KISS stupid
    - Volume control
    - Pitch shift
    - Time shift
- Bro we need wave visualization
- Frequency picker component
    - make it easy to switch between picking in Hz vs notes like C5, A4, that idea
        - should research how note notation works tho